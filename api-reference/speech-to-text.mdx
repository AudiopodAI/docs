---
title: "Speech-to-Text"
description: "Convert audio and video to accurate text transcriptions with speaker identification, timestamps, and multi-language support."
---

## Overview

AudioPod AI's Speech-to-Text API converts audio and video content into accurate text transcriptions using advanced AI models including WhisperX and Faster-Whisper. Get detailed transcriptions with speaker diarization, word-level timestamps, and confidence scores.

### Key Features

- **Multi-Model Support**: WhisperX, Whisper-Timestamped, Faster-Whisper
- **Speaker Diarization**: Automatic speaker identification and separation
- **Word-Level Timestamps**: Precise timing for each word
- **Confidence Scores**: Quality metrics for transcription accuracy
- **50+ Languages**: Automatic language detection or manual specification
- **Large File Support**: Handle videos up to 15 hours with chunking
- **Multiple Sources**: Upload files or provide YouTube/video URLs
- **Editable Transcripts**: Edit and refine transcription results

## Authentication

All endpoints require authentication:
- **API Key**: `Authorization: Bearer your_api_key`
- **JWT Token**: `Authorization: Bearer your_jwt_token`

## Transcribe from URLs

### Transcribe YouTube Videos

Transcribe audio from YouTube or other video platforms.

<Tabs>
  <Tab title="POST">
    ```http
    POST /api/v1/transcription/transcribe
    Authorization: Bearer {api_key}
    Content-Type: application/json
    
    {
      "source_urls": [
        "https://youtube.com/watch?v=example123",
        "https://vimeo.com/123456789"
      ],
      "language": "en",
      "model_type": "whisperx",
      "enable_speaker_diarization": true,
      "min_speakers": 2,
      "max_speakers": 5,
      "enable_word_timestamps": true,
      "enable_confidence_scores": true,
      "chunk_duration": 1800
    }
    ```
  </Tab>
  <Tab title="Python">
    ```python
    import requests
    
    response = requests.post(
        "https://api.audiopod.ai/api/v1/transcription/transcribe",
        headers={"Authorization": f"Bearer {api_key}"},
        json={
            "source_urls": [
                "https://youtube.com/watch?v=example123",
                "https://vimeo.com/123456789"
            ],
            "language": "en",  # Optional: auto-detect if not specified
            "model_type": "whisperx",
            "enable_speaker_diarization": True,
            "min_speakers": 2,
            "max_speakers": 5,
            "enable_word_timestamps": True,
            "enable_confidence_scores": True,
            "chunk_duration": 1800  # 30 minutes
        }
    )
    
    if response.status_code == 200:
        job_data = response.json()
        job_id = job_data["job_id"]
        print(f"Transcription job created: {job_id}")
    ```
  </Tab>
  <Tab title="cURL">
    ```bash
    curl -X POST "https://api.audiopod.ai/api/v1/transcription/transcribe" \
      -H "Authorization: Bearer your_api_key" \
      -H "Content-Type: application/json" \
      -d '{
        "source_urls": ["https://youtube.com/watch?v=example123"],
        "language": "en",
        "model_type": "whisperx",
        "enable_speaker_diarization": true,
        "enable_word_timestamps": true
      }'
    ```
  </Tab>
</Tabs>

**Response:**

```json
{
  "job_id": 123,
  "task_id": "celery_task_uuid_here",
  "status": "PENDING",
  "message": "Transcription job created successfully",
  "estimated_credits": 150,
  "estimated_duration": 1800.0,
  "source_urls": [
    "https://youtube.com/watch?v=example123"
  ]
}
```

## Transcribe from Files

### Upload Audio/Video Files

Transcribe from uploaded audio or video files.

<Tabs>
  <Tab title="POST">
    ```http
    POST /api/v1/transcription/transcribe-upload
    Authorization: Bearer {api_key}
    Content-Type: multipart/form-data
    
    files: (audio/video files)
    language: en
    model_type: whisperx
    enable_speaker_diarization: true
    min_speakers: 1
    max_speakers: 10
    enable_word_timestamps: true
    enable_confidence_scores: true
    chunk_duration: 1800
    ```
  </Tab>
  <Tab title="Python">
    ```python
    files_to_transcribe = [
        "meeting_recording.mp3",
        "interview.wav",
        "presentation.mp4"
    ]
    
    files = []
    for file_path in files_to_transcribe:
        files.append(('files', open(file_path, 'rb')))
    
    response = requests.post(
        "https://api.audiopod.ai/api/v1/transcription/transcribe-upload",
        headers={"Authorization": f"Bearer {api_key}"},
        data={
            "language": "en",
            "model_type": "whisperx",
            "enable_speaker_diarization": True,
            "min_speakers": 1,
            "max_speakers": 10,
            "enable_word_timestamps": True,
            "enable_confidence_scores": True,
            "chunk_duration": 1800
        },
        files=files
    )
    
    # Close files
    for _, file_obj in files:
        file_obj.close()
    
    if response.status_code == 200:
        job_data = response.json()
        print(f"Upload transcription job: {job_data['job_id']}")
    ```
  </Tab>
</Tabs>

## Job Management

### Get Transcription Status

Check the progress and status of transcription jobs.

<Tabs>
  <Tab title="GET">
    ```http
    GET /api/v1/transcription/jobs/{job_id}
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    job_status = response.json()
    print(f"Status: {job_status['status']}")
    print(f"Progress: {job_status['progress']}%")
    
    if job_status["status"] == "COMPLETED":
        print(f"Transcript ready! Duration: {job_status['total_duration']} seconds")
        print(f"Detected language: {job_status['detected_language']}")
        print(f"Confidence: {job_status['confidence_score']}")
    ```
  </Tab>
</Tabs>

**Response (Completed):**

```json
{
  "id": 123,
  "user_id": "550e8400-e29b-41d4-a716-446655440000",
  "source_urls": ["https://youtube.com/watch?v=example123"],
  "language": "en",
  "model_type": "whisperx",
  "enable_speaker_diarization": true,
  "min_speakers": 2,
  "max_speakers": 5,
  "status": "COMPLETED",
  "progress": 100,
  "transcript_path": "/transcripts/job_123.json",
  "total_duration": 1847.5,
  "detected_language": "en",
  "confidence_score": 0.92,
  "created_at": "2024-01-15T10:30:00Z",
  "completed_at": "2024-01-15T10:45:30Z",
  "estimated_credits": 150,
  "display_name": "YouTube Video Transcription"
}
```

### List Transcription Jobs

Get all transcription jobs for the authenticated user.

<Tabs>
  <Tab title="GET">
    ```http
    GET /api/v1/transcription/jobs?status=COMPLETED&limit=50&offset=0
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    response = requests.get(
        "https://api.audiopod.ai/api/v1/transcription/jobs",
        headers={"Authorization": f"Bearer {api_key}"},
        params={
            "status": "COMPLETED",  # Optional filter
            "limit": 50,
            "offset": 0
        }
    )
    
    jobs = response.json()
    for job in jobs:
        print(f"Job {job['id']}: {job['status']} - {job['total_duration']}s")
    ```
  </Tab>
</Tabs>

## Download Transcripts

### Get Transcript in Multiple Formats

Download transcripts in various formats including JSON, TXT, PDF, SRT, VTT, DOCX, and HTML.

<Tabs>
  <Tab title="GET">
    ```http
    GET /api/v1/transcription/jobs/{job_id}/transcript?format=json
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    # Download as JSON with full details
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/transcript",
        headers={"Authorization": f"Bearer {api_key}"},
        params={"format": "json"}
    )
    
    transcript_data = response.json()
    
    # Download as SRT subtitle file
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/transcript",
        headers={"Authorization": f"Bearer {api_key}"},
        params={"format": "srt"}
    )
    
    with open("transcript.srt", "w") as f:
        f.write(response.text)
    
    # Download as PDF document
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/transcript",
        headers={"Authorization": f"Bearer {api_key}"},
        params={"format": "pdf"}
    )
    
    with open("transcript.pdf", "wb") as f:
        f.write(response.content)
    ```
  </Tab>
</Tabs>

**JSON Response Format:**

```json
{
  "job_id": 123,
  "detected_language": "en",
  "confidence_score": 0.92,
  "total_duration": 1847.5,
  "segments": [
    {
      "id": 1,
      "start": 0.0,
      "end": 4.5,
      "text": "Welcome to our podcast about artificial intelligence.",
      "confidence": 0.95,
      "speaker_id": 0,
      "words": [
        {
          "word": "Welcome",
          "start": 0.0,
          "end": 0.8,
          "confidence": 0.98
        },
        {
          "word": "to",
          "start": 0.8,
          "end": 1.0,
          "confidence": 0.99
        }
      ]
    },
    {
      "id": 2,
      "start": 5.0,
      "end": 8.2,
      "text": "Thank you for having me on the show.",
      "confidence": 0.89,
      "speaker_id": 1,
      "words": [...]
    }
  ],
  "speakers": [
    {
      "id": 0,
      "label": "SPEAKER_00",
      "total_speaking_time": 920.3
    },
    {
      "id": 1,
      "label": "SPEAKER_01", 
      "total_speaking_time": 827.2
    }
  ],
  "video_metadata": [
    {
      "video_id": "example123",
      "title": "AI Technology Discussion",
      "description": "A deep dive into AI technology trends",
      "duration": 1847.5,
      "uploader": "Tech Channel",
      "upload_date": "20240115"
    }
  ]
}
```

## Edit Transcripts

### Get Editable Transcript

Retrieve transcript in editable format for corrections.

<Tabs>
  <Tab title="GET">
    ```http
    GET /api/v1/transcription/jobs/{job_id}/edit
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/edit",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    editable_transcript = response.json()
    print(f"Found {len(editable_transcript['segments'])} segments to edit")
    ```
  </Tab>
</Tabs>

### Update Transcript

Submit edited transcript with corrections.

<Tabs>
  <Tab title="PUT">
    ```http
    PUT /api/v1/transcription/jobs/{job_id}/edit
    Authorization: Bearer {api_key}
    Content-Type: application/json
    
    {
      "segments": [
        {
          "id": 1,
          "start": 0.0,
          "end": 4.5,
          "text": "Welcome to our podcast about artificial intelligence.",
          "speaker_label": "SPEAKER_00",
          "confidence": 0.95
        }
      ],
      "edit_notes": "Corrected technical terms and speaker labels"
    }
    ```
  </Tab>
  <Tab title="Python">
    ```python
    # Get current transcript
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/edit",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    transcript = response.json()
    segments = transcript["segments"]
    
    # Make edits
    segments[0]["text"] = "Welcome to our podcast about artificial intelligence."
    segments[0]["speaker_label"] = "Host"
    
    # Submit updates
    response = requests.put(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/edit",
        headers={"Authorization": f"Bearer {api_key}"},
        json={
            "segments": segments,
            "edit_notes": "Corrected speaker labels and technical terms"
        }
    )
    
    if response.status_code == 200:
        update_info = response.json()
        print(f"Updated {update_info['changes_count']} segments")
    ```
  </Tab>
</Tabs>

### Get Transcript Versions

View edit history and versions of transcripts.

<Tabs>
  <Tab title="GET">
    ```http
    GET /api/v1/transcription/jobs/{job_id}/versions
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/versions",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    versions = response.json()
    for version in versions["versions"]:
        print(f"Version {version['version']}: {version['edit_notes']}")
        print(f"  Updated: {version['updated_at']}")
        print(f"  Changes: {version['changes_count']}")
    ```
  </Tab>
</Tabs>

## Extract Audio

### Download Extracted Audio

Get clean audio files extracted from videos during transcription.

<Tabs>
  <Tab title="GET">
    ```http
    GET /api/v1/transcription/jobs/{job_id}/audio/{audio_index}
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    # Download first audio file (index 0)
    response = requests.get(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}/audio/0",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    if response.status_code == 200:
        with open("extracted_audio.wav", "wb") as f:
            f.write(response.content)
        print("Audio file downloaded")
    ```
  </Tab>
</Tabs>

## Delete Jobs

### Delete Transcription Job

Remove transcription jobs and associated data.

<Tabs>
  <Tab title="DELETE">
    ```http
    DELETE /api/v1/transcription/jobs/{job_id}
    Authorization: Bearer {api_key}
    ```
  </Tab>
  <Tab title="Python">
    ```python
    response = requests.delete(
        f"https://api.audiopod.ai/api/v1/transcription/jobs/{job_id}",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    if response.status_code == 204:
        print("Transcription job deleted successfully")
    ```
  </Tab>
</Tabs>

## Supported Languages

AudioPod AI supports automatic language detection or manual specification for 50+ languages:

| Language | Code | Quality | Notes |
|----------|------|---------|-------|
| English | `en` | Excellent | Best supported language |
| Spanish | `es` | Excellent | High accuracy |
| French | `fr` | Excellent | Good speaker diarization |
| German | `de` | Excellent | Technical content support |
| Portuguese | `pt` | Very Good | Brazilian and European |
| Italian | `it` | Very Good | Good word timestamps |
| Russian | `ru` | Very Good | Cyrillic text support |
| Japanese | `ja` | Good | Hiragana/Katakana/Kanji |
| Chinese | `zh` | Good | Simplified and Traditional |
| Arabic | `ar` | Good | RTL text support |
| Hindi | `hi` | Good | Devanagari script |
| Korean | `ko` | Good | Hangul script |

## Model Comparison

Choose the best model for your use case:

| Model | Speed | Accuracy | Speaker Diarization | Best For |
|-------|-------|----------|-------------------|----------|
| **whisperx** | Medium | Highest | Excellent | Production transcription |
| **faster-whisper** | Fastest | High | Good | Real-time applications |
| **whisper-timestamped** | Slow | High | Good | Detailed analysis |

## Best Practices

### Audio Quality Guidelines

For best transcription results:

```python
# Recommended audio specifications
audio_requirements = {
    "sample_rate": "16kHz or higher",
    "format": "WAV, MP3, M4A, or video formats",
    "duration": "Up to 15 hours supported",
    "background_noise": "Minimize for better accuracy",
    "speech_clarity": "Clear articulation preferred",
    "multiple_speakers": "Distinct voices work best"
}

# Chunking for long content
chunking_strategy = {
    "chunk_duration": 1800,  # 30 minutes per chunk
    "overlap": 30,           # 30 seconds overlap
    "boundary_detection": "sentence_level"  # Smart chunk boundaries
}
```

### Cost Optimization

```python
# Efficient transcription workflow
def transcribe_efficiently(audio_files, language="auto"):
    # Use appropriate model based on needs
    model_choice = {
        "speed_priority": "faster-whisper",
        "accuracy_priority": "whisperx", 
        "analysis_priority": "whisper-timestamped"
    }
    
    # Batch similar files together
    batch_files = group_by_language_and_type(audio_files)
    
    for batch in batch_files:
        job = create_transcription_job(
            files=batch,
            language=language,
            model_type=model_choice["accuracy_priority"],
            enable_speaker_diarization=True,
            chunk_duration=1800  # Optimal chunk size
        )
        
        monitor_job_progress(job["job_id"])
```

## Error Handling

<AccordionGroup>
  <Accordion title="400 Bad Request - Invalid Audio">
    **Causes:** - Unsupported audio format - Corrupted audio file - Audio too short 
    **Solutions:** - Use supported formats (WAV, MP3, M4A, MP4) - Verify file integrity - 
    Ensure minimum 10 seconds audio
  </Accordion>

  <Accordion title="413 Payload Too Large">
    **Causes:** - File size exceeds limits - Too many files in single request 
    **Solutions:** - Split large files into smaller chunks - Reduce number of files per request - 
    Use URL transcription for large videos
  </Accordion>

  <Accordion title="422 Processing Error">
    **Causes:** - Audio has no speech content - Extremely poor audio quality 
    **Solutions:** - Verify audio contains speech - Improve audio quality - 
    Try different transcription model
  </Accordion>
</AccordionGroup>

## Pricing

Transcription pricing is based on audio duration:

| Service | Cost | Description |
|---------|------|-------------|
| Basic Transcription | 660 credits/minute | Text-only transcription |
| With Speaker Diarization | 660 credits/minute | Speaker identification included |
| With Word Timestamps | 660 credits/minute | Word-level timing data |
| Transcript Editing | Free | No additional cost for edits |

### Cost Examples

| Duration | Features | Credits | USD Cost |
|----------|----------|---------|----------|
| 10 minutes | Basic transcription | 6600 | $0.88 |
| 30 minutes | With speakers + timestamps | 19800 | $2.64 |
| 1 hour | Full features | 39600 | $5.28 |
| 2 hours | Full features | 79200 | $10.56 |

## Next Steps

<Columns cols={2}>
  <Card title="Speech Translation" icon="language" href="/api-reference/speech-translation">
    Translate transcribed speech while preserving timing and speakers.
  </Card>
  <Card title="Speaker Extraction" icon="users" href="/api-reference/speaker-extraction">
    Extract and separate individual speakers from audio.
  </Card>
</Columns>